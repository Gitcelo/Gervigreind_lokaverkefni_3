{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [FMA: A Dataset For Music Analysis](https://github.com/mdeff/fma)\n",
    "\n",
    "Michaël Defferrard, Kirell Benzi, Pierre Vandergheynst, Xavier Bresson, EPFL LTS2.\n",
    "\n",
    "## Baselines\n",
    "\n",
    "* This notebook evaluates standard classifiers from scikit-learn on the provided features.\n",
    "* Moreover, it evaluates Deep Learning models on both audio and spectrograms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "\n",
    "import IPython.display as ipd\n",
    "from tqdm import tqdm_notebook\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import keras\n",
    "from keras.layers import Activation, Dense, Conv1D, Conv2D, MaxPooling1D, Flatten, Reshape\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.preprocessing import MultiLabelBinarizer, LabelEncoder, LabelBinarizer, StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "#from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "#from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "\nArrays are not equal\n\n(shapes (39665,), (106574,) mismatch)\n x: array([    2,     3,     5, ..., 59318, 59319, 59320], dtype=int64)\n y: array([     2,      3,      5, ..., 155318, 155319, 155320], dtype=int64)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-92-4c26c45ed09e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mfeatures\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'./data/fma_metadata/features.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mechonest\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'./data/fma_metadata/echonest.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtesting\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0massert_array_equal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtracks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;31m#assert echonest.index.isin(tracks.index).all()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mipd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdisplay\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "    \u001b[1;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\numpy\\testing\\_private\\utils.py\u001b[0m in \u001b[0;36massert_array_compare\u001b[1;34m(comparison, x, y, err_msg, verbose, header, precision, equal_nan, equal_inf)\u001b[0m\n\u001b[0;32m    757\u001b[0m                                 \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mheader\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    758\u001b[0m                                 names=('x', 'y'), precision=precision)\n\u001b[1;32m--> 759\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mAssertionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    760\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    761\u001b[0m         \u001b[0mflagged\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbool_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAssertionError\u001b[0m: \nArrays are not equal\n\n(shapes (39665,), (106574,) mismatch)\n x: array([    2,     3,     5, ..., 59318, 59319, 59320], dtype=int64)\n y: array([     2,      3,      5, ..., 155318, 155319, 155320], dtype=int64)"
     ]
    }
   ],
   "source": [
    "AUDIO_DIR = os.environ.get('AUDIO_DIR')\n",
    "\n",
    "tracks = utils.load('./data/fma_metadata/tracks.csv')\n",
    "features = utils.load('./data/fma_metadata/features.csv')\n",
    "echonest = utils.load('./data/fma_metadata/echonest.csv')\n",
    "#np.testing.assert_array_equal(features.index, tracks.index)\n",
    "#assert echonest.index.isin(tracks.index).all()\n",
    "ipd.display(features)\n",
    "tracks.shape, features.shape, echonest.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not enough Echonest features: (11236, 767)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>feature</th>\n",
       "      <th colspan=\"10\" halign=\"left\">chroma_cens</th>\n",
       "      <th>...</th>\n",
       "      <th colspan=\"3\" halign=\"left\">tonnetz</th>\n",
       "      <th colspan=\"7\" halign=\"left\">zcr</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>statistics</th>\n",
       "      <th colspan=\"10\" halign=\"left\">kurtosis</th>\n",
       "      <th>...</th>\n",
       "      <th colspan=\"3\" halign=\"left\">std</th>\n",
       "      <th>kurtosis</th>\n",
       "      <th>max</th>\n",
       "      <th>mean</th>\n",
       "      <th>median</th>\n",
       "      <th>min</th>\n",
       "      <th>skew</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>number</th>\n",
       "      <th>01</th>\n",
       "      <th>02</th>\n",
       "      <th>03</th>\n",
       "      <th>04</th>\n",
       "      <th>05</th>\n",
       "      <th>06</th>\n",
       "      <th>07</th>\n",
       "      <th>08</th>\n",
       "      <th>09</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>04</th>\n",
       "      <th>05</th>\n",
       "      <th>06</th>\n",
       "      <th>01</th>\n",
       "      <th>01</th>\n",
       "      <th>01</th>\n",
       "      <th>01</th>\n",
       "      <th>01</th>\n",
       "      <th>01</th>\n",
       "      <th>01</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>track_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.180653</td>\n",
       "      <td>5.230309</td>\n",
       "      <td>0.249321</td>\n",
       "      <td>1.347620</td>\n",
       "      <td>1.482478</td>\n",
       "      <td>0.531371</td>\n",
       "      <td>1.481593</td>\n",
       "      <td>2.691455</td>\n",
       "      <td>0.866868</td>\n",
       "      <td>1.341231</td>\n",
       "      <td>...</td>\n",
       "      <td>0.054125</td>\n",
       "      <td>0.012226</td>\n",
       "      <td>0.012111</td>\n",
       "      <td>5.758890</td>\n",
       "      <td>0.459473</td>\n",
       "      <td>0.085629</td>\n",
       "      <td>0.071289</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.089872</td>\n",
       "      <td>0.061448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.888963</td>\n",
       "      <td>0.760539</td>\n",
       "      <td>0.345297</td>\n",
       "      <td>2.295201</td>\n",
       "      <td>1.654031</td>\n",
       "      <td>0.067592</td>\n",
       "      <td>1.366848</td>\n",
       "      <td>1.054094</td>\n",
       "      <td>0.108103</td>\n",
       "      <td>0.619185</td>\n",
       "      <td>...</td>\n",
       "      <td>0.063831</td>\n",
       "      <td>0.014212</td>\n",
       "      <td>0.017740</td>\n",
       "      <td>2.824694</td>\n",
       "      <td>0.466309</td>\n",
       "      <td>0.084578</td>\n",
       "      <td>0.063965</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.716724</td>\n",
       "      <td>0.069330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.527563</td>\n",
       "      <td>-0.077654</td>\n",
       "      <td>-0.279610</td>\n",
       "      <td>0.685883</td>\n",
       "      <td>1.937570</td>\n",
       "      <td>0.880839</td>\n",
       "      <td>-0.923192</td>\n",
       "      <td>-0.927232</td>\n",
       "      <td>0.666617</td>\n",
       "      <td>1.038546</td>\n",
       "      <td>...</td>\n",
       "      <td>0.040730</td>\n",
       "      <td>0.012691</td>\n",
       "      <td>0.014759</td>\n",
       "      <td>6.808415</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.053114</td>\n",
       "      <td>0.041504</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.193303</td>\n",
       "      <td>0.044861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>3.702245</td>\n",
       "      <td>-0.291193</td>\n",
       "      <td>2.196742</td>\n",
       "      <td>-0.234449</td>\n",
       "      <td>1.367364</td>\n",
       "      <td>0.998411</td>\n",
       "      <td>1.770694</td>\n",
       "      <td>1.604566</td>\n",
       "      <td>0.521217</td>\n",
       "      <td>1.982386</td>\n",
       "      <td>...</td>\n",
       "      <td>0.074358</td>\n",
       "      <td>0.017952</td>\n",
       "      <td>0.013921</td>\n",
       "      <td>21.434212</td>\n",
       "      <td>0.452148</td>\n",
       "      <td>0.077515</td>\n",
       "      <td>0.071777</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.542325</td>\n",
       "      <td>0.040800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>-0.193837</td>\n",
       "      <td>-0.198527</td>\n",
       "      <td>0.201546</td>\n",
       "      <td>0.258556</td>\n",
       "      <td>0.775204</td>\n",
       "      <td>0.084794</td>\n",
       "      <td>-0.289294</td>\n",
       "      <td>-0.816410</td>\n",
       "      <td>0.043851</td>\n",
       "      <td>-0.804761</td>\n",
       "      <td>...</td>\n",
       "      <td>0.095003</td>\n",
       "      <td>0.022492</td>\n",
       "      <td>0.021355</td>\n",
       "      <td>16.669037</td>\n",
       "      <td>0.469727</td>\n",
       "      <td>0.047225</td>\n",
       "      <td>0.040039</td>\n",
       "      <td>0.000977</td>\n",
       "      <td>3.189831</td>\n",
       "      <td>0.030993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59316</th>\n",
       "      <td>-0.481064</td>\n",
       "      <td>-0.295152</td>\n",
       "      <td>-0.322082</td>\n",
       "      <td>-0.488209</td>\n",
       "      <td>-0.783982</td>\n",
       "      <td>-0.758057</td>\n",
       "      <td>-0.172649</td>\n",
       "      <td>-0.574800</td>\n",
       "      <td>-0.567931</td>\n",
       "      <td>-0.106916</td>\n",
       "      <td>...</td>\n",
       "      <td>0.189431</td>\n",
       "      <td>0.030145</td>\n",
       "      <td>0.025107</td>\n",
       "      <td>57.463642</td>\n",
       "      <td>0.247559</td>\n",
       "      <td>0.019898</td>\n",
       "      <td>0.017578</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.752326</td>\n",
       "      <td>0.013561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59317</th>\n",
       "      <td>-0.743582</td>\n",
       "      <td>-0.605692</td>\n",
       "      <td>-0.836542</td>\n",
       "      <td>-0.681023</td>\n",
       "      <td>-0.571624</td>\n",
       "      <td>0.146994</td>\n",
       "      <td>-0.411660</td>\n",
       "      <td>-0.774929</td>\n",
       "      <td>-0.566724</td>\n",
       "      <td>-0.662409</td>\n",
       "      <td>...</td>\n",
       "      <td>0.162859</td>\n",
       "      <td>0.027939</td>\n",
       "      <td>0.027151</td>\n",
       "      <td>10.608624</td>\n",
       "      <td>0.354004</td>\n",
       "      <td>0.067627</td>\n",
       "      <td>0.063965</td>\n",
       "      <td>0.009766</td>\n",
       "      <td>2.388833</td>\n",
       "      <td>0.037579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59318</th>\n",
       "      <td>-0.707417</td>\n",
       "      <td>-0.907697</td>\n",
       "      <td>-0.797663</td>\n",
       "      <td>0.498702</td>\n",
       "      <td>-0.745043</td>\n",
       "      <td>-0.861259</td>\n",
       "      <td>-1.010390</td>\n",
       "      <td>-1.022202</td>\n",
       "      <td>-0.589689</td>\n",
       "      <td>-0.445751</td>\n",
       "      <td>...</td>\n",
       "      <td>0.131089</td>\n",
       "      <td>0.026251</td>\n",
       "      <td>0.024088</td>\n",
       "      <td>14.704644</td>\n",
       "      <td>0.342773</td>\n",
       "      <td>0.046808</td>\n",
       "      <td>0.041504</td>\n",
       "      <td>0.004883</td>\n",
       "      <td>2.878773</td>\n",
       "      <td>0.030992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59319</th>\n",
       "      <td>-0.945818</td>\n",
       "      <td>-1.051203</td>\n",
       "      <td>-0.624787</td>\n",
       "      <td>0.683686</td>\n",
       "      <td>-0.174416</td>\n",
       "      <td>-0.284828</td>\n",
       "      <td>-0.548947</td>\n",
       "      <td>-0.316935</td>\n",
       "      <td>-0.685450</td>\n",
       "      <td>-0.855717</td>\n",
       "      <td>...</td>\n",
       "      <td>0.144943</td>\n",
       "      <td>0.028384</td>\n",
       "      <td>0.027911</td>\n",
       "      <td>10.670013</td>\n",
       "      <td>0.423340</td>\n",
       "      <td>0.047649</td>\n",
       "      <td>0.036621</td>\n",
       "      <td>0.000977</td>\n",
       "      <td>2.571443</td>\n",
       "      <td>0.040549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59320</th>\n",
       "      <td>-1.192956</td>\n",
       "      <td>-1.115285</td>\n",
       "      <td>-0.782962</td>\n",
       "      <td>-0.547290</td>\n",
       "      <td>-0.906612</td>\n",
       "      <td>-0.706638</td>\n",
       "      <td>-0.227156</td>\n",
       "      <td>-0.596657</td>\n",
       "      <td>-0.247576</td>\n",
       "      <td>-0.998426</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>39665 rows × 518 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "feature    chroma_cens                                                    \\\n",
       "statistics    kurtosis                                                     \n",
       "number              01        02        03        04        05        06   \n",
       "track_id                                                                   \n",
       "2             7.180653  5.230309  0.249321  1.347620  1.482478  0.531371   \n",
       "3             1.888963  0.760539  0.345297  2.295201  1.654031  0.067592   \n",
       "5             0.527563 -0.077654 -0.279610  0.685883  1.937570  0.880839   \n",
       "10            3.702245 -0.291193  2.196742 -0.234449  1.367364  0.998411   \n",
       "20           -0.193837 -0.198527  0.201546  0.258556  0.775204  0.084794   \n",
       "...                ...       ...       ...       ...       ...       ...   \n",
       "59316        -0.481064 -0.295152 -0.322082 -0.488209 -0.783982 -0.758057   \n",
       "59317        -0.743582 -0.605692 -0.836542 -0.681023 -0.571624  0.146994   \n",
       "59318        -0.707417 -0.907697 -0.797663  0.498702 -0.745043 -0.861259   \n",
       "59319        -0.945818 -1.051203 -0.624787  0.683686 -0.174416 -0.284828   \n",
       "59320        -1.192956 -1.115285 -0.782962 -0.547290 -0.906612 -0.706638   \n",
       "\n",
       "feature                                             ...   tonnetz            \\\n",
       "statistics                                          ...       std             \n",
       "number            07        08        09        10  ...        04        05   \n",
       "track_id                                            ...                       \n",
       "2           1.481593  2.691455  0.866868  1.341231  ...  0.054125  0.012226   \n",
       "3           1.366848  1.054094  0.108103  0.619185  ...  0.063831  0.014212   \n",
       "5          -0.923192 -0.927232  0.666617  1.038546  ...  0.040730  0.012691   \n",
       "10          1.770694  1.604566  0.521217  1.982386  ...  0.074358  0.017952   \n",
       "20         -0.289294 -0.816410  0.043851 -0.804761  ...  0.095003  0.022492   \n",
       "...              ...       ...       ...       ...  ...       ...       ...   \n",
       "59316      -0.172649 -0.574800 -0.567931 -0.106916  ...  0.189431  0.030145   \n",
       "59317      -0.411660 -0.774929 -0.566724 -0.662409  ...  0.162859  0.027939   \n",
       "59318      -1.010390 -1.022202 -0.589689 -0.445751  ...  0.131089  0.026251   \n",
       "59319      -0.548947 -0.316935 -0.685450 -0.855717  ...  0.144943  0.028384   \n",
       "59320      -0.227156 -0.596657 -0.247576 -0.998426  ...       NaN       NaN   \n",
       "\n",
       "feature                     zcr                                          \\\n",
       "statistics             kurtosis       max      mean    median       min   \n",
       "number            06         01        01        01        01        01   \n",
       "track_id                                                                  \n",
       "2           0.012111   5.758890  0.459473  0.085629  0.071289  0.000000   \n",
       "3           0.017740   2.824694  0.466309  0.084578  0.063965  0.000000   \n",
       "5           0.014759   6.808415  0.375000  0.053114  0.041504  0.000000   \n",
       "10          0.013921  21.434212  0.452148  0.077515  0.071777  0.000000   \n",
       "20          0.021355  16.669037  0.469727  0.047225  0.040039  0.000977   \n",
       "...              ...        ...       ...       ...       ...       ...   \n",
       "59316       0.025107  57.463642  0.247559  0.019898  0.017578  0.000000   \n",
       "59317       0.027151  10.608624  0.354004  0.067627  0.063965  0.009766   \n",
       "59318       0.024088  14.704644  0.342773  0.046808  0.041504  0.004883   \n",
       "59319       0.027911  10.670013  0.423340  0.047649  0.036621  0.000977   \n",
       "59320            NaN        NaN       NaN       NaN       NaN       NaN   \n",
       "\n",
       "feature                         \n",
       "statistics      skew       std  \n",
       "number            01        01  \n",
       "track_id                        \n",
       "2           2.089872  0.061448  \n",
       "3           1.716724  0.069330  \n",
       "5           2.193303  0.044861  \n",
       "10          3.542325  0.040800  \n",
       "20          3.189831  0.030993  \n",
       "...              ...       ...  \n",
       "59316       5.752326  0.013561  \n",
       "59317       2.388833  0.037579  \n",
       "59318       2.878773  0.030992  \n",
       "59319       2.571443  0.040549  \n",
       "59320            NaN       NaN  \n",
       "\n",
       "[39665 rows x 518 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "((25000, 52), (25000, 518))"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subset = tracks.index[tracks['set', 'subset'] <= 'medium']\n",
    "#assert subset.isin(tracks.index).all()\n",
    "#assert subset.isin(features.index).all()\n",
    "features_all = features.join(echonest, how='inner').sort_index(axis=1)\n",
    "print('Not enough Echonest features: {}'.format(features_all.shape))\n",
    "tracks = tracks.loc[subset]\n",
    "features_all = features.reindex([subset])\n",
    "tracks.shape, features_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19922 training examples, 2505 validation examples, 2573 testing examples\n",
      "Top genres (16): ['Blues', 'Classical', 'Country', 'Easy Listening', 'Electronic', 'Experimental', 'Folk', 'Hip-Hop', 'Instrumental', 'International', 'Jazz', 'Old-Time / Historic', 'Pop', 'Rock', 'Soul-RnB', 'Spoken']\n",
      "All genres (151): [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 25, 26, 27, 30, 31, 32, 33, 36, 37, 38, 41, 42, 43, 45, 46, 47, 49, 53, 58, 63, 64, 65, 66, 70, 71, 74, 76, 77, 79, 81, 83, 85, 86, 88, 89, 90, 92, 94, 97, 98, 100, 101, 102, 103, 107, 109, 111, 113, 117, 118, 125, 130, 137, 138, 166, 167, 169, 171, 172, 174, 177, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 214, 224, 232, 236, 240, 247, 250, 267, 286, 296, 297, 311, 314, 322, 337, 359, 360, 361, 362, 374, 378, 400, 401, 404, 428, 439, 440, 441, 442, 443, 456, 468, 491, 495, 502, 504, 514, 524, 538, 539, 542, 580, 602, 619, 651, 659, 695, 741, 763, 808, 810, 811, 906, 1032, 1060, 1193, 1235]\n"
     ]
    }
   ],
   "source": [
    "train = tracks.index[tracks['set', 'split'] == 'training']\n",
    "val = tracks.index[tracks['set', 'split'] == 'validation']\n",
    "test = tracks.index[tracks['set', 'split'] == 'test']\n",
    "print('{} training examples, {} validation examples, {} testing examples'.format(*map(len, [train, val, test])))\n",
    "genres = list(LabelEncoder().fit(tracks['track', 'genre_top']).classes_)\n",
    "#genres = list(tracks['track', 'genre_top'].unique())\n",
    "print('Top genres ({}): {}'.format(len(genres), genres))\n",
    "genres = list(MultiLabelBinarizer().fit(tracks['track', 'genres_all']).classes_)\n",
    "print('All genres ({}): {}'.format(len(genres), genres))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Multiple classifiers and feature sets\n",
    "\n",
    "Todo:\n",
    "* Cross-validation for hyper-parameters.\n",
    "* Dimensionality reduction?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_process(tracks, features, columns, multi_label=False, verbose=False):\n",
    "    if not multi_label:\n",
    "        # Assign an integer value to each genre.\n",
    "        enc = LabelEncoder()\n",
    "        labels = tracks['track', 'genre_top']\n",
    "        #y = enc.fit_transform(tracks['track', 'genre_top'])\n",
    "    else:\n",
    "        # Create an indicator matrix.\n",
    "        enc = MultiLabelBinarizer()\n",
    "        labels = tracks['track', 'genres_all']\n",
    "        #labels = tracks['track', 'genres']\n",
    "    # Split in training, validation and testing sets.\n",
    "    y_train = enc.fit_transform(labels[train])\n",
    "    ipd.display(features)\n",
    "    y_val = enc.transform(labels[val])\n",
    "    y_test = enc.transform(labels[test])\n",
    "    X_train = features.loc[train, columns]\n",
    "    X_val = features.loc[val, columns].to_numpy()\n",
    "    X_test = features.loc[test, columns].to_numpy()\n",
    "    X_train, y_train = shuffle(X_train, y_train, random_state=42)\n",
    "    # Standardize features by removing the mean and scaling to unit variance.\n",
    "    scaler = StandardScaler(copy=False)\n",
    "    scaler.fit_transform(X_train)\n",
    "    scaler.transform(X_val)\n",
    "    scaler.transform(X_test)\n",
    "    \n",
    "    return y_train, y_val, y_test, X_train, X_val, X_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Single genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_classifiers_features(classifiers, feature_sets, multi_label=False):\n",
    "    columns = list(classifiers.keys()).insert(0, 'dim')\n",
    "    scores = pd.DataFrame(columns=columns, index=feature_sets.keys())\n",
    "    times = pd.DataFrame(columns=classifiers.keys(), index=feature_sets.keys())\n",
    "    for fset_name, fset in tqdm_notebook(feature_sets.items(), desc='features'):\n",
    "        y_train, y_val, y_test, X_train, X_val, X_test = pre_process(tracks, features_all, fset, multi_label)\n",
    "        scores.loc[fset_name, 'dim'] = X_train.shape[1]\n",
    "        for clf_name, clf in classifiers.items():  # tqdm_notebook(classifiers.items(), desc='classifiers', leave=False):\n",
    "            t = time.process_time()\n",
    "            clf.fit(X_train, y_train)\n",
    "            score = clf.score(X_test, y_test)\n",
    "            scores.loc[fset_name, clf_name] = score\n",
    "            times.loc[fset_name, clf_name] = time.process_time() - t\n",
    "    return scores, times\n",
    "\n",
    "def format_scores(scores):\n",
    "    def highlight(s):\n",
    "        is_max = s == max(s[1:])\n",
    "        return ['background-color: yellow' if v else '' for v in is_max]\n",
    "    scores = scores.style.apply(highlight, axis=1)\n",
    "    return scores.format('{:.2%}', subset=pd.IndexSlice[:, scores.columns[1]:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-86-9aaf4f0488ea>:5: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for fset_name, fset in tqdm_notebook(feature_sets.items(), desc='features'):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c42cf5c83e5b4e849aff4b054c207023",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='features'), FloatProgress(value=0.0, max=18.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>feature</th>\n",
       "      <th colspan=\"10\" halign=\"left\">chroma_cens</th>\n",
       "      <th>...</th>\n",
       "      <th colspan=\"3\" halign=\"left\">tonnetz</th>\n",
       "      <th colspan=\"7\" halign=\"left\">zcr</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>statistics</th>\n",
       "      <th colspan=\"10\" halign=\"left\">kurtosis</th>\n",
       "      <th>...</th>\n",
       "      <th colspan=\"3\" halign=\"left\">std</th>\n",
       "      <th>kurtosis</th>\n",
       "      <th>max</th>\n",
       "      <th>mean</th>\n",
       "      <th>median</th>\n",
       "      <th>min</th>\n",
       "      <th>skew</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>number</th>\n",
       "      <th>01</th>\n",
       "      <th>02</th>\n",
       "      <th>03</th>\n",
       "      <th>04</th>\n",
       "      <th>05</th>\n",
       "      <th>06</th>\n",
       "      <th>07</th>\n",
       "      <th>08</th>\n",
       "      <th>09</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>04</th>\n",
       "      <th>05</th>\n",
       "      <th>06</th>\n",
       "      <th>01</th>\n",
       "      <th>01</th>\n",
       "      <th>01</th>\n",
       "      <th>01</th>\n",
       "      <th>01</th>\n",
       "      <th>01</th>\n",
       "      <th>01</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>track_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155297</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155298</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155306</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155307</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155314</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25000 rows × 518 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "feature    chroma_cens                                      ... tonnetz      \\\n",
       "statistics    kurtosis                                      ...     std       \n",
       "number              01  02  03  04  05  06  07  08  09  10  ...      04  05   \n",
       "track_id                                                    ...               \n",
       "2                  NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN  ...     NaN NaN   \n",
       "3                  NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN  ...     NaN NaN   \n",
       "5                  NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN  ...     NaN NaN   \n",
       "10                 NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN  ...     NaN NaN   \n",
       "134                NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN  ...     NaN NaN   \n",
       "...                ...  ..  ..  ..  ..  ..  ..  ..  ..  ..  ...     ...  ..   \n",
       "155297             NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN  ...     NaN NaN   \n",
       "155298             NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN  ...     NaN NaN   \n",
       "155306             NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN  ...     NaN NaN   \n",
       "155307             NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN  ...     NaN NaN   \n",
       "155314             NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN  ...     NaN NaN   \n",
       "\n",
       "feature             zcr                               \n",
       "statistics     kurtosis max mean median min skew std  \n",
       "number      06       01  01   01     01  01   01  01  \n",
       "track_id                                              \n",
       "2          NaN      NaN NaN  NaN    NaN NaN  NaN NaN  \n",
       "3          NaN      NaN NaN  NaN    NaN NaN  NaN NaN  \n",
       "5          NaN      NaN NaN  NaN    NaN NaN  NaN NaN  \n",
       "10         NaN      NaN NaN  NaN    NaN NaN  NaN NaN  \n",
       "134        NaN      NaN NaN  NaN    NaN NaN  NaN NaN  \n",
       "...         ..      ...  ..  ...    ...  ..  ...  ..  \n",
       "155297     NaN      NaN NaN  NaN    NaN NaN  NaN NaN  \n",
       "155298     NaN      NaN NaN  NaN    NaN NaN  NaN NaN  \n",
       "155306     NaN      NaN NaN  NaN    NaN NaN  NaN NaN  \n",
       "155307     NaN      NaN NaN  NaN    NaN NaN  NaN NaN  \n",
       "155314     NaN      NaN NaN  NaN    NaN NaN  NaN NaN  \n",
       "\n",
       "[25000 rows x 518 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jgh06\\anaconda3\\lib\\site-packages\\sklearn\\utils\\extmath.py:770: RuntimeWarning: invalid value encountered in true_divide\n",
      "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
      "C:\\Users\\jgh06\\anaconda3\\lib\\site-packages\\sklearn\\utils\\extmath.py:711: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  result = op(x, *args, **kwargs)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float64').",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-87-5b2a008ffb67>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     34\u001b[0m     \u001b[1;34m'all_non-echonest'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlevels\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m })\n\u001b[1;32m---> 36\u001b[1;33m \u001b[0mscores\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest_classifiers_features\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclassifiers\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeature_sets\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     37\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[0mipd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdisplay\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mformat_scores\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-86-9aaf4f0488ea>\u001b[0m in \u001b[0;36mtest_classifiers_features\u001b[1;34m(classifiers, feature_sets, multi_label)\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mclf_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclf\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mclassifiers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# tqdm_notebook(classifiers.items(), desc='classifiers', leave=False):\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m             \u001b[0mt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprocess_time\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m             \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m             \u001b[0mscore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m             \u001b[0mscores\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfset_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclf_name\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscore\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m   1340\u001b[0m             \u001b[0m_dtype\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1341\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1342\u001b[1;33m         X, y = self._validate_data(X, y, accept_sparse='csr', dtype=_dtype,\n\u001b[0m\u001b[0;32m   1343\u001b[0m                                    \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"C\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1344\u001b[0m                                    accept_large_sparse=solver != 'liblinear')\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    430\u001b[0m                 \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    431\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 432\u001b[1;33m                 \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    433\u001b[0m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    434\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     70\u001b[0m                           FutureWarning)\n\u001b[0;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[0;32m    793\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"y cannot be None\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    794\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 795\u001b[1;33m     X = check_array(X, accept_sparse=accept_sparse,\n\u001b[0m\u001b[0;32m    796\u001b[0m                     \u001b[0maccept_large_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maccept_large_sparse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    797\u001b[0m                     \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     70\u001b[0m                           FutureWarning)\n\u001b[0;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[0;32m    642\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    643\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 644\u001b[1;33m             _assert_all_finite(array,\n\u001b[0m\u001b[0;32m    645\u001b[0m                                allow_nan=force_all_finite == 'allow-nan')\n\u001b[0;32m    646\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[1;34m(X, allow_nan, msg_dtype)\u001b[0m\n\u001b[0;32m     94\u001b[0m                 not allow_nan and not np.isfinite(X).all()):\n\u001b[0;32m     95\u001b[0m             \u001b[0mtype_err\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'infinity'\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mallow_nan\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m'NaN, infinity'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 96\u001b[1;33m             raise ValueError(\n\u001b[0m\u001b[0;32m     97\u001b[0m                     \u001b[0mmsg_err\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     98\u001b[0m                     (type_err,\n",
      "\u001b[1;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float64')."
     ]
    }
   ],
   "source": [
    "classifiers = {\n",
    "    'LR': LogisticRegression(),\n",
    "    'kNN': KNeighborsClassifier(n_neighbors=200),\n",
    "    'SVCrbf': SVC(kernel='rbf'),\n",
    "    'SVCpoly1': SVC(kernel='poly', degree=1),\n",
    "    'linSVC1': SVC(kernel=\"linear\"),\n",
    "    'linSVC2': LinearSVC(),\n",
    "    #GaussianProcessClassifier(1.0 * RBF(1.0), warm_start=True),\n",
    "    'DT': DecisionTreeClassifier(max_depth=5),\n",
    "    'RF': RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1),\n",
    "    'AdaBoost': AdaBoostClassifier(n_estimators=10),\n",
    "    'MLP1': MLPClassifier(hidden_layer_sizes=(100,), max_iter=2000),\n",
    "    'MLP2': MLPClassifier(hidden_layer_sizes=(200, 50), max_iter=2000),\n",
    "    'NB': GaussianNB(),\n",
    "    'QDA': QuadraticDiscriminantAnalysis(),\n",
    "}\n",
    "\n",
    "feature_sets = {\n",
    "#    'echonest_audio': ('echonest', 'audio_features'),\n",
    "#    'echonest_social': ('echonest', 'social_features'),\n",
    "#    'echonest_temporal': ('echonest', 'temporal_features'),\n",
    "#    'echonest_audio/social': ('echonest', ('audio_features', 'social_features')),\n",
    "#    'echonest_all': ('echonest', ('audio_features', 'social_features', 'temporal_features')),\n",
    "}\n",
    "for name in features.columns.levels[0]:\n",
    "    feature_sets[name] = name\n",
    "feature_sets.update({\n",
    "    'mfcc/contrast': ['mfcc', 'spectral_contrast'],\n",
    "    'mfcc/contrast/chroma': ['mfcc', 'spectral_contrast', 'chroma_cens'],\n",
    "    'mfcc/contrast/centroid': ['mfcc', 'spectral_contrast', 'spectral_centroid'],\n",
    "    'mfcc/contrast/chroma/centroid': ['mfcc', 'spectral_contrast', 'chroma_cens', 'spectral_centroid'],\n",
    "    'mfcc/contrast/chroma/centroid/tonnetz': ['mfcc', 'spectral_contrast', 'chroma_cens', 'spectral_centroid', 'tonnetz'],\n",
    "    'mfcc/contrast/chroma/centroid/zcr': ['mfcc', 'spectral_contrast', 'chroma_cens', 'spectral_centroid', 'zcr'],\n",
    "    'all_non-echonest': list(features.columns.levels[0])\n",
    "})\n",
    "scores, times = test_classifiers_features(classifiers, feature_sets)\n",
    "\n",
    "ipd.display(format_scores(scores))\n",
    "ipd.display(times.style.format('{:.4f}'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Multiple genres\n",
    "\n",
    "Todo:\n",
    "* Ignore rare genres? Count them higher up in the genre tree? On the other hand it's not much tracks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = {\n",
    "    #LogisticRegression(),\n",
    "    'LR': OneVsRestClassifier(LogisticRegression()),\n",
    "    'SVC': OneVsRestClassifier(SVC()),\n",
    "    'MLP': MLPClassifier(max_iter=700),\n",
    "}\n",
    "\n",
    "feature_sets = {\n",
    "#    'echonest_audio': ('echonest', 'audio_features'),\n",
    "#    'echonest_temporal': ('echonest', 'temporal_features'),\n",
    "    'mfcc': 'mfcc',\n",
    "    'mfcc/contrast/chroma/centroid/tonnetz': ['mfcc', 'spectral_contrast', 'chroma_cens', 'spectral_centroid', 'tonnetz'],\n",
    "    'mfcc/contrast/chroma/centroid/zcr': ['mfcc', 'spectral_contrast', 'chroma_cens', 'spectral_centroid', 'zcr'],\n",
    "}\n",
    "\n",
    "scores, times = test_classifiers_features(classifiers, feature_sets, multi_label=True)\n",
    "\n",
    "ipd.display(format_scores(scores))\n",
    "ipd.display(times.style.format('{:.4f}'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Deep learning on raw audio\n",
    "\n",
    "Other architectures:\n",
    "* [Learning Features of Music from Scratch (MusicNet)](https://arxiv.org/abs/1611.09827), John Thickstun, Zaid Harchaoui, Sham Kakade."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_onehot = LabelBinarizer().fit_transform(tracks['track', 'genre_top'])\n",
    "labels_onehot = pd.DataFrame(labels_onehot, index=tracks.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load audio samples in parallel using `multiprocessing` so as to maximize CPU usage when decoding MP3s and making some optional pre-processing. There are multiple ways to load a waveform from a compressed MP3:\n",
    "* librosa uses audioread in the backend which can use many native libraries, e.g. ffmpeg\n",
    "    * resampling is very slow --> use `kaiser_fast`\n",
    "    * does not work with multi-processing, for keras `fit_generator()`\n",
    "* pydub is a high-level interface for audio modification, uses ffmpeg to load\n",
    "    * store a temporary `.wav`\n",
    "* directly pipe ffmpeg output\n",
    "    * fastest method\n",
    "* [pyAV](https://github.com/mikeboers/PyAV) may be a fastest alternative by linking to ffmpeg libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just be sure that everything is fine. Multiprocessing is tricky to debug.\n",
    "utils.FfmpegLoader().load(utils.get_audio_path(AUDIO_DIR, 2))\n",
    "SampleLoader = utils.build_sample_loader(AUDIO_DIR, labels_onehot, utils.FfmpegLoader())\n",
    "SampleLoader(train, batch_size=2).__next__()[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keras parameters.\n",
    "NB_WORKER = len(os.sched_getaffinity(0))  # number of usables CPUs\n",
    "params = {'pickle_safe': True, 'nb_worker': NB_WORKER, 'max_q_size': 10}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Fully connected neural network\n",
    "\n",
    "* Two layers with 10 hiddens is no better than random, ~11%.\n",
    "\n",
    "Optimize data loading to be CPU / GPU bound, not IO bound. Larger batches means reduced training time, so increase batch time until memory exhaustion. Number of workers and queue size have no influence on speed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = utils.FfmpegLoader(sampling_rate=2000)\n",
    "SampleLoader = utils.build_sample_loader(AUDIO_DIR, labels_onehot, loader)\n",
    "print('Dimensionality: {}'.format(loader.shape))\n",
    "\n",
    "keras.backend.clear_session()\n",
    "\n",
    "model = keras.models.Sequential()\n",
    "model.add(Dense(output_dim=1000, input_shape=loader.shape))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(Dense(output_dim=100))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(Dense(output_dim=labels_onehot.shape[1]))\n",
    "model.add(Activation(\"softmax\"))\n",
    "\n",
    "optimizer = keras.optimizers.SGD(lr=0.1, momentum=0.9, nesterov=True)\n",
    "model.compile(optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit_generator(SampleLoader(train, batch_size=64), train.size, nb_epoch=2, **params)\n",
    "loss = model.evaluate_generator(SampleLoader(val, batch_size=64), val.size, **params)\n",
    "loss = model.evaluate_generator(SampleLoader(test, batch_size=64), test.size, **params)\n",
    "#Y = model.predict_generator(SampleLoader(test, batch_size=64), test.size, **params);\n",
    "\n",
    "loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Convolutional neural network\n",
    "\n",
    "* Architecture: [End-to-end learning for music audio](http://www.mirlab.org/conference_papers/International_Conference/ICASSP%202014/papers/p7014-dieleman.pdf), Sander Dieleman, Benjamin Schrauwen.\n",
    "* Missing: track segmentation and class averaging (majority voting)\n",
    "* Compared with log-scaled mel-spectrograms instead of strided convolution as first layer.\n",
    "* Larger net: http://benanne.github.io/2014/08/05/spotify-cnns.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = utils.FfmpegLoader(sampling_rate=16000)\n",
    "#loader = utils.LibrosaLoader(sampling_rate=16000)\n",
    "SampleLoader = utils.build_sample_loader(AUDIO_DIR, labels_onehot, loader)\n",
    "\n",
    "keras.backend.clear_session()\n",
    "\n",
    "model = keras.models.Sequential()\n",
    "model.add(Reshape((-1, 1), input_shape=loader.shape))\n",
    "print(model.output_shape)\n",
    "\n",
    "model.add(Conv1D(128, 512, subsample_length=512))\n",
    "print(model.output_shape)\n",
    "model.add(Activation(\"relu\"))\n",
    "\n",
    "model.add(Conv1D(32, 8))\n",
    "print(model.output_shape)\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(MaxPooling1D(4))\n",
    "\n",
    "model.add(Conv1D(32, 8))\n",
    "print(model.output_shape)\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(MaxPooling1D(4))\n",
    "\n",
    "print(model.output_shape)\n",
    "#model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "print(model.output_shape)\n",
    "model.add(Dense(100))\n",
    "model.add(Activation(\"relu\"))\n",
    "print(model.output_shape)\n",
    "model.add(Dense(labels_onehot.shape[1]))\n",
    "model.add(Activation(\"softmax\"))\n",
    "print(model.output_shape)\n",
    "\n",
    "optimizer = keras.optimizers.SGD(lr=0.01, momentum=0.9, nesterov=True)\n",
    "#optimizer = keras.optimizers.Adam()#lr=1e-5)#, momentum=0.9, nesterov=True)\n",
    "model.compile(optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit_generator(SampleLoader(train, batch_size=10), train.size, nb_epoch=20, **params)\n",
    "loss = model.evaluate_generator(SampleLoader(val, batch_size=10), val.size, **params)\n",
    "loss = model.evaluate_generator(SampleLoader(test, batch_size=10), test.size, **params)\n",
    "\n",
    "loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Recurrent neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Deep learning on extracted audio features\n",
    "\n",
    "Look at:\n",
    "* Pre-processing in Keras: https://github.com/keunwoochoi/kapre\n",
    "* Convolutional Recurrent Neural Networks for Music Classification: https://github.com/keunwoochoi/icassp_2017\n",
    "* Music Auto-Tagger: https://github.com/keunwoochoi/music-auto_tagging-keras\n",
    "* Pre-processor: https://github.com/bmcfee/pumpp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 ConvNet on MFCC\n",
    "\n",
    "* Architecture: [Automatic Musical Pattern Feature Extraction Using Convolutional Neural Network](http://www.iaeng.org/publication/IMECS2010/IMECS2010_pp546-550.pdf), Tom LH. Li, Antoni B. Chan and Andy HW. Chun\n",
    "* Missing: track segmentation and majority voting.\n",
    "* Best seen: 17.6%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MfccLoader(utils.Loader):\n",
    "    raw_loader = utils.FfmpegLoader(sampling_rate=22050)\n",
    "    #shape = (13, 190)  # For segmented tracks.\n",
    "    shape = (13, 2582)\n",
    "    def load(self, filename):\n",
    "        import librosa\n",
    "        x = self.raw_loader.load(filename)\n",
    "        # Each MFCC frame spans 23ms on the audio signal with 50% overlap with the adjacent frames.\n",
    "        mfcc = librosa.feature.mfcc(x, sr=22050, n_mfcc=13, n_fft=512, hop_length=256)\n",
    "        return mfcc\n",
    "\n",
    "loader = MfccLoader()\n",
    "SampleLoader = utils.build_sample_loader(AUDIO_DIR, labels_onehot, loader)\n",
    "loader.load(utils.get_audio_path(AUDIO_DIR, 2))[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "\n",
    "model = keras.models.Sequential()\n",
    "model.add(Reshape((*loader.shape, 1),  input_shape=loader.shape))\n",
    "print(model.output_shape)\n",
    "\n",
    "model.add(Conv2D(3, 13, 10, subsample=(1, 4)))\n",
    "model.add(Activation(\"relu\"))\n",
    "print(model.output_shape)\n",
    "\n",
    "model.add(Conv2D(15, 1, 10, subsample=(1, 4)))\n",
    "model.add(Activation(\"relu\"))\n",
    "print(model.output_shape)\n",
    "\n",
    "model.add(Conv2D(65, 1, 10, subsample=(1, 4)))\n",
    "model.add(Activation(\"relu\"))\n",
    "print(model.output_shape)\n",
    "\n",
    "model.add(Flatten())\n",
    "print(model.output_shape)\n",
    "model.add(Dense(labels_onehot.shape[1]))\n",
    "model.add(Activation(\"softmax\"))\n",
    "print(model.output_shape)\n",
    "\n",
    "optimizer = keras.optimizers.SGD(1e-3)#lr=0.01, momentum=0.9, nesterov=True)\n",
    "#optimizer = keras.optimizers.Adam()#lr=1e-5)#\n",
    "model.compile(optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit_generator(SampleLoader(train, batch_size=16), train.size, nb_epoch=20, **params)\n",
    "loss = model.evaluate_generator(SampleLoader(val, batch_size=16), val.size, **params)\n",
    "loss = model.evaluate_generator(SampleLoader(test, batch_size=16), test.size, **params)\n",
    "#Y = model.predict_generator(loader, test.size, pickle_safe=True, nb_worker=NB_WORKER, max_q_size=5)\n",
    "\n",
    "loss"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
